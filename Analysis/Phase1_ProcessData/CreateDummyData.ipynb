{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Define Settings for Data Dictionary\n",
    "output_path='/home/jovyan/cmip6-outreach-tool/data/'\n",
    "this_experiment_id = ['historical','ssp126', 'ssp370','ssp245','ssp585']\n",
    "this_variable_id = 'tas'\n",
    "this_table_id = 'Amon'\n",
    "this_grid_label='gn'\n",
    "\n",
    "\n",
    "######## Load Packages\n",
    "import xarray as xr\n",
    "import intake\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import xesmf as xe\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "import util \n",
    "\n",
    "######### Create Data Dictionary\n",
    "import CreateDataDict\n",
    "[dataset_info, dset_dict, modelnames]=CreateDataDict.createDataDict(this_experiment_id, this_variable_id, this_table_id, this_grid_label)\n",
    "\n",
    "######### Create Functions\n",
    "### Create ds_out reference file\n",
    "def CreateReferenceGrid(modelname, experiment_id,activity_id):\n",
    "    dataset_info_subset = dataset_info[dataset_info['source_id']==modelname]\n",
    "    institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "    nametag=activity_id+'.'+institution_id+'.'+modelname+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "    thisdata=dset_dict[nametag]\n",
    "    ds_out = xr.Dataset({'lat': thisdata['lat'],\n",
    "                         'lon': thisdata['lon']})\n",
    "    return ds_out\n",
    "\n",
    "def RegridModel(thisdata,latvariable='lat',lonvariable='lon'):\n",
    "    ds_in = xr.Dataset({'lat': thisdata[latvariable],\n",
    "                    'lon': thisdata[lonvariable],\n",
    "                    'time': thisdata['time'],\n",
    "                    this_variable_id: thisdata[this_variable_id]})\n",
    "    regridder = xe.Regridder(ds_in, ds_out, 'nearest_s2d')\n",
    "    thisdata_regridded = regridder(ds_in)\n",
    "    thisdata_regridded.attrs.update(thisdata.attrs)\n",
    "    return thisdata_regridded\n",
    "\n",
    "def reindex_time(startingtimes):\n",
    "    newtimes = startingtimes.values\n",
    "    for i in range(0,len(startingtimes)):\n",
    "        yr = int(str(startingtimes.values[i])[0:4])\n",
    "        mon = int(str(startingtimes.values[i])[5:7])\n",
    "        day = int(str(startingtimes.values[i])[8:10])\n",
    "        hr = int(str(startingtimes.values[i])[11:13])\n",
    "        newdate = cftime.DatetimeProlepticGregorian(yr,mon,15)\n",
    "        newtimes[i]=newdate\n",
    "    return newtimes\n",
    "\n",
    "def initializeDataSet(activity_id,experiment_id,modelname):\n",
    "    dataset_info_subset = dataset_info[dataset_info['source_id']==modelname]\n",
    "    institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "    nametag=activity_id+'.'+institution_id+'.'+modelname+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "    thisdata=dset_dict[nametag]\n",
    "    thisdata=xr.decode_cf(thisdata)\n",
    "    thisdata = thisdata.mean(dim=['member_id'])\n",
    "    ###### Reformat dates to be Proleptic Gregorian date type\n",
    "    newtimes = reindex_time(startingtimes = thisdata['time'])\n",
    "    thistime = xr.DataArray(newtimes, coords=[newtimes], dims=['time'])\n",
    "    thisdata['time'] = thistime\n",
    "    thisdata=thisdata.groupby('time.year').mean('time')\n",
    "    thisdata.load()\n",
    "    ###### Regrid \n",
    "    \n",
    "    #########################################\n",
    "    thisval=thisdata[this_variable_id] #.mean(dim=['lat','lon'])\n",
    "    ds = xr.Dataset({modelname: thisval},\\\n",
    "                    coords={'time': thistime})\n",
    "                            #'modelnames': modelnameInd, \\\n",
    "                            #'lat': thislat, \\\n",
    "                            #'lon': thislon, \\\n",
    "                \n",
    "    return ds\n",
    "\n",
    "def fillDataSet():\n",
    "    modelnames_toplot = []\n",
    "    for modelname in modelnames:\n",
    "        source_id = modelname\n",
    "        dataset_info_subset = dataset_info[dataset_info['source_id']==source_id]\n",
    "        institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "        nametag = activity_id+'.'+institution_id+'.'+source_id+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "        if nametag in dset_dict:\n",
    "            \n",
    "            ######### A BUNCH OF EXCEPTIONS WHERE THINGS BREAK ###############\n",
    "            if (modelname=='MCM-UA-1-0'):\n",
    "                # ERROR Different names for lat and lon\n",
    "                print('** Skipping '+modelname)\n",
    "            elif (experiment_id=='historical')and(modelname=='CESM2'):\n",
    "                #ValueError: cannot reindex or align along dimension 'time' because the index has duplicate values\n",
    "                print('** Skipping '+modelname)\n",
    "            elif (experiment_id=='ssp126')and(modelname=='CanESM5'):\n",
    "                #OutOfBoundsDatetime: Cannot decode times from a non-standard calendar, '365_day', using pandas.\n",
    "                print('** Skipping '+modelname)\n",
    "            elif (experiment_id=='ssp370')and(modelname=='CESM2-WACCM'):\n",
    "                #ValueError: cannot reindex or align along dimension 'time' because the index has duplicate values\n",
    "                print('** Skipping '+modelname)\n",
    "            elif (experiment_id=='ssp245')and ((modelname=='CAMS-CSM1-0')or (modelname=='HadGEM3-GC31-LL')):\n",
    "                print('** Skipping '+modelname)\n",
    "            elif (experiment_id=='ssp585')and((modelname=='CAMS-CSM1-0')or(modelname=='CanESM5')):\n",
    "                print('** Skipping '+modelname)\n",
    "            \n",
    "            ###### Reformat dates to be Proleptic Gregorian date type\n",
    "            else:\n",
    "                print(modelname)\n",
    "                print(ds.nbytes/1e9)\n",
    "                modelnames_toplot.append(modelname)\n",
    "                thisdata=dset_dict[nametag]\n",
    "                thisdata=xr.decode_cf(thisdata)\n",
    "                thisdata = thisdata.mean(dim=['member_id'])\n",
    "                newtimes = reindex_time(startingtimes = thisdata['time'])\n",
    "                thisdata['time'] = xr.DataArray(newtimes, coords=[newtimes], dims=['time'])\n",
    "                ###### Regrid this\n",
    "                thisdata=RegridModel(thisdata)\n",
    "                thisdata=thisdata.groupby('time.year').mean('time')\n",
    "                thisdata.load() #if this is commented out, lazily loading and will be dask function call\n",
    "                thisval=thisdata[this_variable_id] #.mean(dim=['lat','lon'])\n",
    "                ds[modelname]=thisval\n",
    "    return ds,modelnames_toplot\n",
    "\n",
    "########### Main Workflow\n",
    "dict_timeSeries = dict()\n",
    "\n",
    "for scenario in this_experiment_id:\n",
    "    experiment_id = scenario\n",
    "    print('---------------'+experiment_id+'---------------')\n",
    "    if experiment_id=='historical':\n",
    "        activity_id='CMIP'\n",
    "    else:\n",
    "        activity_id='ScenarioMIP'\n",
    "    ds= initializeDataSet(activity_id,experiment_id,modelname='CAMS-CSM1-0')\n",
    "    ds_out = CreateReferenceGrid(modelname='CAMS-CSM1-0', activity_id = 'CMIP', experiment_id='historical')\n",
    "    \n",
    "    # read data from all other models into xarray dataset\n",
    "    [ds,modelnames_toplot] = fillDataSet()\n",
    "    \n",
    "     # Convert from K to C\n",
    "    for modelname in modelnames_toplot:\n",
    "        ds[modelname]=ds[modelname]-273.15\n",
    "\n",
    "    #Add dataset to dictionary\n",
    "    dict_timeSeries[experiment_id] = ds\n",
    "    dict_timeSeries[experiment_id+'_modelnameToPlot'] = modelnames_toplot\n",
    "    \n",
    "    #save ds\n",
    "    with open(output_path+'timeSeries_byModel_'+scenario+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(ds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
